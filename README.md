# Data-Leakage-From-Covariances
Privacy-preserving distributed modelling approaches, such as Federated Learning, are becoming increasingly relevant for analyzing sensitive data. Conceptually, these approaches facilitate an integrative data analysis without sharing the data, which is highly beneficial for application areas such as medicine. Yet, the risk of data leakage from malicious attacks needs to be carefully studied. 
Here, we take the perspective of a malicious client and present an attacking algorithm that builds on sample means, sample covariances, and creating known linearly independent vectors on the server-side. We show that already with these functionalities, which are available in most federated analysis frameworks, privacy-protected data can be exactly reconstructed. We demonstrate this limitation of existing frameworks and discuss possible defense strategies.

# Link to Paper
